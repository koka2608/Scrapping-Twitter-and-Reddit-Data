{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e6c41a",
   "metadata": {},
   "source": [
    "# Reddit Data Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026da5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.5.0-py3-none-any.whl (176 kB)\n",
      "Collecting websocket-client>=0.54.0\n",
      "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
      "Collecting update-checker>=0.18\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Collecting prawcore<3,>=2.1\n",
      "  Downloading prawcore-2.3.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\ameya\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ameya\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ameya\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ameya\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\ameya\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (4.0.0)\n",
      "Installing collected packages: websocket-client, update-checker, prawcore, praw\n",
      "Successfully installed praw-7.5.0 prawcore-2.3.0 update-checker-0.18.0 websocket-client-1.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#As its name suggests PRAW is a Python wrapper for the Reddit API,\n",
    "# which enables you to scrape data from subreddits, create a bot and much more.\n",
    "# In this article, we will learn how to use PRAW to scrape posts from different subreddits as well as\n",
    "# how to get comments from a specific post.\n",
    "pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfc026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required packages\n",
    "\n",
    "import praw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9009fced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27b8f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-only instance\n",
    "reddit_read_only = praw.Reddit(client_id=\"LNrSvS-Z5ZawFF7OmOhjeA\",         # your client id.. The one below'personl use script'\n",
    "                               client_secret=\"-nTtowdd1alINiqr72ukovMlrCoTIA\",      # your client secret\n",
    "                               user_agent=\"Stock Webscrapping\")        # your user agent or name in the app\n",
    " \n",
    "# Authorized instance\n",
    "reddit_authorized = praw.Reddit(client_id=\"LNrSvS-Z5ZawFF7OmOhjeA\",         # your client id\n",
    "                                client_secret=\"-nTtowdd1alINiqr72ukovMlrCoTIA\",      # your client secret\n",
    "                                user_agent=\"Stock Webscrapping\",        # your user agent\n",
    "                                username=\"koka2608\",        # your reddit username\n",
    "                                password=\"Ameya@2608\")        # your reddit password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575cbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0993321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display Name: redditdev\n",
      "Title: reddit Development\n",
      "Description: A subreddit for discussion of Reddit's API and Reddit API clients.\n",
      "\n",
      "* [Read the API Overview & Rules](https://github.com/reddit/reddit/wiki/API)\n",
      "* [Check out the API documentation](http://www.reddit.com/dev/api)\n",
      "* [PRAW chat](https://join.slack.com/t/praw/shared_invite/enQtOTUwMDcxOTQ0NzY5LWVkMGQ3ZDk5YmQ5MDEwYTZmMmJkMTJkNjBkNTY3OTU0Y2E2NGRlY2ZhZTAzMWZmMWRiMTMwYjdjODkxOGYyZjY)\n",
      "* [Snoowrap chat](https://gitter.im/not-an-aardvark/snoowrap)\n",
      "* [Unofficial Discord](https://discord.gg/hVMhxpV)\n",
      "* Please do not request bots here. Consider /r/requestabot instead.\n",
      "\n",
      "\n",
      "Please confine discussion to Reddit's API instead of using this as a soapbox to talk to the admins. In particular, use [/r/ideasfortheadmins](/r/ideasfortheadmins) for feature ideas and [/r/bugs](/r/bugs) for bugs. If you have general reddit questions, try [/r/help](/r/help).\n",
      "\n",
      "To see an explanation of recent user-facing changes to reddit (and the code behind them), check out /r/changelog.\n",
      "\n",
      "---\n",
      "\n",
      "To report a security issue with reddit, please send an email to <security@reddit.com> .\n",
      "\n",
      "This is an admin-sponsored subreddit.\n"
     ]
    }
   ],
   "source": [
    "subreddit = reddit_read_only.subreddit(\"redditdev\")\n",
    " \n",
    "# Display the name of the Subreddit\n",
    "print(\"Display Name:\", subreddit.display_name)\n",
    " \n",
    "# Display the title of the Subreddit\n",
    "print(\"Title:\", subreddit.title)\n",
    " \n",
    "# Display the description of the Subreddit\n",
    "print(\"Description:\", subreddit.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c14327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.I. insurance firm Tractable marks \"unicorn\" status as it expands from cars into property claims\n",
      "\n",
      "24-year-old podcaster turned VC scores $140 million from MIT, Spotify backer to invest\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "subreddit = reddit_read_only.subreddit(\"fortune\")\n",
    " \n",
    "for post in subreddit.hot(limit=5):\n",
    "    print(post.title)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "211a5ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>ID</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Score</th>\n",
       "      <th>Total Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.I. insurance firm Tractable marks \"unicorn\" ...</td>\n",
       "      <td></td>\n",
       "      <td>o1zozs</td>\n",
       "      <td>https://fortune.com/2021/06/16/tractable-unico...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24-year-old podcaster turned VC scores $140 mi...</td>\n",
       "      <td></td>\n",
       "      <td>o1zk6j</td>\n",
       "      <td>https://fortune.com/2021/06/16/harry-stebbings...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Post Text      ID  \\\n",
       "0  A.I. insurance firm Tractable marks \"unicorn\" ...            o1zozs   \n",
       "1  24-year-old podcaster turned VC scores $140 mi...            o1zk6j   \n",
       "\n",
       "                                            Post URL  Score  Total Comments  \n",
       "0  https://fortune.com/2021/06/16/tractable-unico...      1               0  \n",
       "1  https://fortune.com/2021/06/16/harry-stebbings...      1               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = subreddit.top(\"month\")\n",
    "# Scraping the top posts of the current month\n",
    " \n",
    "posts_dict = {\"Title\": [], \"Post Text\": [], \"ID\":[],\n",
    "              \"Post URL\":[], \"Score\":[],\n",
    "               \n",
    "              \"Total Comments\": [] \n",
    "              }\n",
    " \n",
    "for post in posts:\n",
    "    # Title of each post\n",
    "    posts_dict[\"Title\"].append(post.title)\n",
    "     \n",
    "    # Text inside a post\n",
    "    posts_dict[\"Post Text\"].append(post.selftext)\n",
    "     \n",
    "    # Unique ID of each post\n",
    "    posts_dict[\"ID\"].append(post.id)\n",
    "     \n",
    "    # The score of a post\n",
    "    posts_dict[\"Score\"].append(post.score)\n",
    "     \n",
    "    # Total number of comments inside the post\n",
    "    posts_dict[\"Total Comments\"].append(post.num_comments)\n",
    "     \n",
    "    # URL of each post\n",
    "    posts_dict[\"Post URL\"].append(post.url)\n",
    " \n",
    "# Saving the data in a pandas dataframe\n",
    "top_posts = pd.DataFrame(posts_dict)\n",
    "top_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c88d43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = top_posts.to_csv(\"Top Posts.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642da054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799dc929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
